{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "A4K6_4QjFu7Z"
      },
      "outputs": [],
      "source": [
        "!pip install -q gradio soundfile numpy scipy sqlalchemy python-dotenv pydub librosa requests\n",
        "# Optional heavy libs if you want HF/transformers locally (GPU required)\n",
        "# !pip install -q transformers accelerate diffusers \"huggingface_hub>=0.10.0\" replicate openai sentence-transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "QCQCy1dnFWwI"
      },
      "outputs": [],
      "source": [
        "# AI Music & Voice Generator\n",
        "# Usage: set HF_TOKEN and REPLICATE_API_TOKEN as environment variables if you want heavy models.\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=SyntaxWarning)  # SyntaxWarning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "sE-0kaPcFu-Y"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import io\n",
        "import uuid\n",
        "import time\n",
        "import json\n",
        "import sqlite3\n",
        "import base64\n",
        "import random\n",
        "import logging\n",
        "import shutil\n",
        "from pathlib import Path\n",
        "from typing import Optional\n",
        "\n",
        "import numpy as np\n",
        "import soundfile as sf\n",
        "from pydub import AudioSegment  # optional helper (kept for future use)\n",
        "import gradio as gr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "sMb8-T3cFvBU"
      },
      "outputs": [],
      "source": [
        "#  Config / Tokens\n",
        "\n",
        "HUGGINGFACE_TOKEN = os.environ.get(\"\", \"\")  # set in environment for HF usage\n",
        "REPLICATE_TOKEN = os.environ.get(\"REPLICATE_API_TOKEN\", \"\")  # set in environment for Replicate usage\n",
        "\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "logger = logging.getLogger(\"ai music voice\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "vdnihwZUFvEp"
      },
      "outputs": [],
      "source": [
        "# Directories & DB init\n",
        "\n",
        "DATA_DIR = Path(\"ai_music_voice_data\")\n",
        "AUDIO_DIR = DATA_DIR / \"audio\"\n",
        "DB_PATH = DATA_DIR / \"meta.db\"\n",
        "DATA_DIR.mkdir(exist_ok=True)\n",
        "AUDIO_DIR.mkdir(exist_ok=True)\n",
        "\n",
        "# Simple sqlite DB to record generations\n",
        "conn = sqlite3.connect(DB_PATH, check_same_thread=False)\n",
        "c = conn.cursor()\n",
        "c.execute(\n",
        "    \"\"\"\n",
        "    CREATE TABLE IF NOT EXISTS generations (\n",
        "        id TEXT PRIMARY KEY,\n",
        "        kind TEXT,\n",
        "        prompt TEXT,\n",
        "        voice_sample_path TEXT,\n",
        "        file_path TEXT,\n",
        "        provider TEXT,\n",
        "        created_at REAL\n",
        "    )\n",
        "    \"\"\"\n",
        ")\n",
        "conn.commit()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "oXs8h9SQFvHZ"
      },
      "outputs": [],
      "source": [
        "# Procedural / offline generators\n",
        "\n",
        "def synth_simple_music(duration_sec: int = 20, bpm: int = 100, seed: Optional[int] = None) -> str:\n",
        "    \"\"\"\n",
        "    Procedural background music generator -> writes WAV and returns path.\n",
        "    Simple pad + chord progression, offline (no external APIs).\n",
        "    \"\"\"\n",
        "    if seed is not None:\n",
        "        random.seed(seed)\n",
        "        np.random.seed(seed)\n",
        "\n",
        "    sr = 24000\n",
        "    t = np.linspace(0, duration_sec, int(sr * duration_sec), endpoint=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "UZBFI5KDFvKD"
      },
      "outputs": [],
      "source": [
        "def synth_simple_music(duration_sec: int = 20, bpm: int = 100, seed: Optional[int] = None) -> str:\n",
        "    \"\"\"\n",
        "    Procedural background music generator -> writes WAV and returns path.\n",
        "    Simple pad + chord progression, offline (no external APIs).\n",
        "    \"\"\"\n",
        "    if seed is not None:\n",
        "        random.seed(seed)\n",
        "        np.random.seed(seed)\n",
        "\n",
        "    sr = 24000\n",
        "    t = np.linspace(0, duration_sec, int(sr * duration_sec), endpoint=False)\n",
        "\n",
        "    # simple chord palette (triads)\n",
        "    base_freqs = [\n",
        "        [261.63, 329.63, 392.00],  # C major-ish\n",
        "        [293.66, 369.99, 440.00],  # D minor-ish\n",
        "        [329.63, 415.30, 493.88],  # E-ish\n",
        "        [349.23, 440.00, 523.25],  # F major-ish\n",
        "    ]\n",
        "\n",
        "    pad = np.zeros_like(t)\n",
        "    block_len = int(len(t) / len(base_freqs))\n",
        "\n",
        "    for ci, freqs in enumerate(base_freqs):\n",
        "        start = ci * block_len\n",
        "        end = start + block_len if ci < len(base_freqs) - 1 else len(t)\n",
        "        seg_t = t[start:end]\n",
        "        s = np.zeros_like(seg_t)\n",
        "        for f in freqs:\n",
        "            detune = random.uniform(-1.0, 1.0)\n",
        "            s += 0.3 * np.sin(2 * np.pi * (f + detune) * seg_t)\n",
        "        # short fade in/out envelope for each block\n",
        "        env = np.ones_like(s)\n",
        "        ramp = max(1, int(len(s) * 0.05))\n",
        "        env[:ramp] *= np.linspace(0, 1, ramp)\n",
        "        env[-ramp:] *= np.linspace(1, 0, ramp) # Corrected fade-out\n",
        "        pad[start:end] += s * env\n",
        "\n",
        "    # mild reverb-ish convolution with exponential kernel\n",
        "    kernel = np.exp(-np.linspace(0, 2, 800))\n",
        "    pad = np.convolve(pad, kernel, mode=\"same\")\n",
        "    pad = pad / (np.max(np.abs(pad)) + 1e-9) * 0.6\n",
        "\n",
        "    out_path = AUDIO_DIR / f\"music_proc_{int(time.time())}.wav\"\n",
        "    sf.write(str(out_path), pad.astype(np.float32), sr)\n",
        "    return str(out_path)\n",
        "\n",
        "def synth_simple_voice(prompt_text: str, voice_seed: Optional[int] = None) -> str:\n",
        "    \"\"\"\n",
        "    Lightweight synthetic 'singing' voice: maps token sequence to simple sine-note sequence.\n",
        "    Offline, deterministic-ish if seed provided.\n",
        "    \"\"\"\n",
        "    if voice_seed is not None:\n",
        "        random.seed(voice_seed)\n",
        "        np.random.seed(voice_seed)\n",
        "\n",
        "    sr = 24000\n",
        "    tokens = prompt_text.split()\n",
        "    syl = max(1, min(60, len(tokens)))\n",
        "    duration = 2.5 + syl * 0.12\n",
        "    t = np.linspace(0, duration, int(sr * duration), endpoint=False)\n",
        "    mel = np.zeros_like(t)\n",
        "\n",
        "    samples_per_token = max(1, int(len(t) / len(tokens)))\n",
        "    for i, token in enumerate(tokens):\n",
        "        f = 220 + (i % 12) * 30  # simple scale mapping\n",
        "        start = i * samples_per_token\n",
        "        end = min(len(t), start + samples_per_token)\n",
        "        seg_len = end - start\n",
        "        if seg_len <= 0:\n",
        "            continue\n",
        "        seg_t = np.linspace(0, seg_len / sr, seg_len, endpoint=False)\n",
        "        env = np.hanning(len(seg_t))\n",
        "        mel[start:end] += 0.5 * env * np.sin(2 * np.pi * f * seg_t)\n",
        "\n",
        "    mel = mel + 0.01 * np.random.randn(len(mel))\n",
        "    mel = mel / (np.max(np.abs(mel)) + 1e-9) * 0.7\n",
        "    out_path = AUDIO_DIR / f\"voice_proc_{int(time.time())}.wav\"\n",
        "    sf.write(str(out_path), mel.astype(np.float32), sr)\n",
        "    return str(out_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "hLrzZ7HXFvM4"
      },
      "outputs": [],
      "source": [
        "# Heavy model templates (placeholders) -- require tokens\n",
        "\n",
        "def generate_music_hf_inference(prompt: str, duration: int = 10) -> str:\n",
        "    \"\"\"\n",
        "    Template for Hugging Face Inference API usage.\n",
        "    NOTE: This is a minimal template — adjust endpoint/model and parameters per chosen model.\n",
        "    \"\"\"\n",
        "    if not HUGGINGFACE_TOKEN:\n",
        "        raise RuntimeError(\"Hugging Face token not set (HF_TOKEN).\")\n",
        "    import requests\n",
        "\n",
        "    headers = {\"Authorization\": f\"Bearer {HUGGINGFACE_TOKEN}\"}\n",
        "    api_url = \"https://api-inference.huggingface.co/models/facebook/musicgen-small\"  # example\n",
        "    payload = {\"inputs\": prompt, \"parameters\": {\"duration\": duration}}\n",
        "    r = requests.post(api_url, headers=headers, json=payload)\n",
        "    if r.status_code != 200:\n",
        "        raise RuntimeError(f\"HuggingFace API error: {r.status_code} {r.text}\")\n",
        "\n",
        "    out_path = AUDIO_DIR / f\"music_hf_{int(time.time())}.wav\"\n",
        "    with open(out_path, \"wb\") as f:\n",
        "        f.write(r.content)\n",
        "    return str(out_path)\n",
        "\n",
        "\n",
        "def generate_music_replicate(prompt: str, duration: int = 10) -> str:\n",
        "    \"\"\"\n",
        "    Template for Replicate model usage.\n",
        "    NOTE: replace model slug and handling as per the actual model's output format.\n",
        "    \"\"\"\n",
        "    if not REPLICATE_TOKEN:\n",
        "        raise RuntimeError(\"REPLICATE_API_TOKEN not set.\")\n",
        "    try:\n",
        "        import replicate\n",
        "        client = replicate.Client(api_token=REPLICATE_TOKEN)\n",
        "        # model slug here is placeholder\n",
        "        model = client.models.get(\"suno/musicgen-small\")\n",
        "        output = model.predict(prompt=prompt, duration=duration)\n",
        "        # assume output contains a URL as first element\n",
        "        url = output[0]\n",
        "        import requests\n",
        "        r = requests.get(url)\n",
        "        out_path = AUDIO_DIR / f\"music_repl_{int(time.time())}.wav\"\n",
        "        with open(out_path, \"wb\") as f:\n",
        "            f.write(r.content)\n",
        "        return str(out_path)\n",
        "    except Exception as e:\n",
        "        raise RuntimeError(\"Replicate integration failed: \" + str(e))\n",
        "\n",
        "\n",
        "def generate_voice_bark_replicate(text: str, voice_sample_path: Optional[str] = None) -> str:\n",
        "    \"\"\"\n",
        "    Template for calling a voice synthesis/cloning model on Replicate.\n",
        "    Replace model slug and inputs per actual model spec.\n",
        "    \"\"\"\n",
        "    if not REPLICATE_TOKEN:\n",
        "        raise RuntimeError(\"REPLICATE_API_TOKEN not set.\")\n",
        "    try:\n",
        "        import replicate\n",
        "        client = replicate.Client(api_token=REPLICATE_TOKEN)\n",
        "        # placeholder slug — change to real model\n",
        "        model = client.models.get(\"example/bark-v1\")\n",
        "        inputs = {\"text\": text}\n",
        "        if voice_sample_path:\n",
        "            inputs[\"voice_sample\"] = open(voice_sample_path, \"rb\")\n",
        "        output = model.predict(**inputs)\n",
        "        url = output[0]\n",
        "        import requests\n",
        "        r = requests.get(url)\n",
        "        out_path = AUDIO_DIR / f\"voice_repl_{int(time.time())}.wav\"\n",
        "        with open(out_path, \"wb\") as f:\n",
        "            f.write(r.content)\n",
        "        return str(out_path)\n",
        "    except Exception as e:\n",
        "        raise RuntimeError(\"Replicate Bark template failed: \" + str(e))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "cjf_oj-9FvP3"
      },
      "outputs": [],
      "source": [
        "# Helpers: DB register\n",
        "\n",
        "def register_generation(kind: str, prompt: str, file_path: str, provider: str = \"procedural\") -> str:\n",
        "    gen_id = str(uuid.uuid4())\n",
        "    created = time.time()\n",
        "    c.execute(\n",
        "        \"INSERT INTO generations (id, kind, prompt, voice_sample_path, file_path, provider, created_at) VALUES (?,?,?,?,?,?,?)\",\n",
        "        (gen_id, kind, prompt, None, file_path, provider, created),\n",
        "    )\n",
        "    conn.commit()\n",
        "    return gen_id"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "qbfB6AMSFvSv"
      },
      "outputs": [],
      "source": [
        "# UI functions (wired to Gradio)\n",
        "\n",
        "def ui_generate_music(prompt, duration, use_heavy, provider_choice):\n",
        "    try:\n",
        "        if use_heavy and provider_choice == \"hf\":\n",
        "            path = generate_music_hf_inference(prompt, duration=int(duration))\n",
        "            provider = \"hf_musicgen\"\n",
        "        elif use_heavy and provider_choice == \"replicate\":\n",
        "            path = generate_music_replicate(prompt, duration=int(duration))\n",
        "            provider = \"replicate_musicgen\"\n",
        "        else:\n",
        "            path = synth_simple_music(duration_sec=int(duration))\n",
        "            provider = \"procedural\"\n",
        "        gen_id = register_generation(\"music\", prompt, path, provider)\n",
        "        return f\"Generated music (id={gen_id}) using {provider}\", path\n",
        "    except Exception as e:\n",
        "        logger.exception(\"Music generation error\")\n",
        "        return f\"Error: {str(e)}\", None\n",
        "\n",
        "\n",
        "def ui_generate_voice(prompt, voice_upload, use_heavy, provider_choice):\n",
        "    try:\n",
        "        sample_path = None\n",
        "        # Gradio may send np array, file path, or file-like — handle common cases\n",
        "        if voice_upload is not None:\n",
        "            if isinstance(voice_upload, tuple) and len(voice_upload) == 2:\n",
        "                # (sample_rate, np_array)\n",
        "                sr, arr = voice_upload\n",
        "                sample_path = AUDIO_DIR / f\"voice_sample_{int(time.time())}.wav\"\n",
        "                sf.write(str(sample_path), np.array(arr), sr)\n",
        "                sample_path = str(sample_path)\n",
        "            elif isinstance(voice_upload, str) and os.path.exists(voice_upload):\n",
        "                sample_path = str(AUDIO_DIR / f\"voice_sample_copy_{int(time.time())}.wav\")\n",
        "                shutil.copy(voice_upload, sample_path)\n",
        "            else:\n",
        "                # fallback: try to read bytes and write to file\n",
        "                try:\n",
        "                    fp = AUDIO_DIR / f\"voice_sample_{int(time.time())}.wav\"\n",
        "                    with open(fp, \"wb\") as f:\n",
        "                        if hasattr(voice_upload, \"read\"):\n",
        "                            f.write(voice_upload.read())\n",
        "                            sample_path = str(fp)\n",
        "                except Exception:\n",
        "                    sample_path = None\n",
        "\n",
        "        if use_heavy and provider_choice == \"replicate\":\n",
        "            out_path = generate_voice_bark_replicate(prompt, voice_sample_path=sample_path)\n",
        "            provider = \"replicate_bark\"\n",
        "        else:\n",
        "            out_path = synth_simple_voice(prompt)\n",
        "            provider = \"procedural_tts\"\n",
        "        gen_id = register_generation(\"voice\", prompt, out_path, provider)\n",
        "        return f\"Voice generated (id={gen_id}) using {provider}\", out_path\n",
        "    except Exception as e:\n",
        "        logger.exception(\"Voice generation error\")\n",
        "        return f\"Error: {str(e)}\", None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "aO2on5dvFvVm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 628
        },
        "outputId": "cba02615-7237-4c01-a925-5f37bbebdeb5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://b25d4b87481048c237.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://b25d4b87481048c237.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Demo launched. If running in Colab you will see a Gradio link above.\n"
          ]
        }
      ],
      "source": [
        "# Build Gradio UI and wire up button click handlers\n",
        "\n",
        "def build_and_launch(share: bool = True, inbrowser: bool = False):\n",
        "    with gr.Blocks() as demo:\n",
        "        gr.Markdown(\"# AI Music & Voice Generator — Prototype (Clean)\")\n",
        "\n",
        "        with gr.Tab(\"Music Generator\"):\n",
        "            prompt_m = gr.Textbox(lines=3, label=\"Music Prompt (describe mood/instruments)\", value=\"Calm ambient pad with gentle bells\")\n",
        "            duration = gr.Slider(5, 120, value=20, step=5, label=\"Duration (sec)\")\n",
        "            use_heavy_music = gr.Checkbox(label=\"Use heavy model (MusicGen/Riffusion) if available\", value=False)\n",
        "            provider_music = gr.Radio([\"procedural\", \"hf\", \"replicate\"], value=\"procedural\", label=\"Provider (hf/replicate/procedural)\")\n",
        "            btn_m = gr.Button(\"Generate Music\")\n",
        "            out_msg_m = gr.Textbox(label=\"Status\")\n",
        "            out_audio_m = gr.Audio(label=\"Generated Music\")\n",
        "\n",
        "        with gr.Tab(\"Voice / Singer Generator\"):\n",
        "            prompt_v = gr.Textbox(lines=3, label=\"Lyrics or text to sing/voice\", value=\"Hello world, this is a demo singing line.\")\n",
        "            voice_sample = gr.Audio(type=\"numpy\", label=\"Upload voice sample for cloning (optional)\")\n",
        "            use_heavy_voice = gr.Checkbox(label=\"Use heavy model (Bark/VALL-E/RVC) if available\", value=False)\n",
        "            provider_voice = gr.Radio([\"procedural\", \"replicate\"], value=\"procedural\", label=\"Provider\")\n",
        "            btn_v = gr.Button(\"Generate Voice\")\n",
        "            out_msg_v = gr.Textbox(label=\"Status\")\n",
        "            out_audio_v = gr.Audio(label=\"Generated Voice\")\n",
        "\n",
        "        btn_m.click(fn=ui_generate_music,\n",
        "                    inputs=[prompt_m, duration, use_heavy_music, provider_music],\n",
        "                    outputs=[out_msg_m, out_audio_m])\n",
        "        btn_v.click(fn=ui_generate_voice,\n",
        "                    inputs=[prompt_v, voice_sample, use_heavy_voice, provider_voice],\n",
        "                    outputs=[out_msg_v, out_audio_v])\n",
        "\n",
        "    demo.launch(share=share, inbrowser=inbrowser)\n",
        "    print(\"Demo launched. If running in Colab you will see a Gradio link above.\")\n",
        "\n",
        "\n",
        "# If this file is run as a script, start the UI\n",
        "if __name__ == \"__main__\":\n",
        "    build_and_launch(share=True, inbrowser=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mowXWQ9sFvYE"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FHZaSPOfFva2"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}